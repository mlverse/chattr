[{"path":"https://mlverse.github.io/chattr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 chattr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"Interact with local models","text":"LlamaGPT-Chat command line chat application. integrates LLM via C++. means work LLM’s language. available today free download use. C++, models able run locally computer, even GPU available. models quite fast responses. integrating LlamaGPT-Chat, able access multiple types LLM’s one additional back-end within chattr.","code":""},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Interact with local models","text":"get LlamaGPT-Chat working machine need two things: version LlamaGPT-Chat works computer LLM file works chat program","code":""},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"install-llamagpt-chat","dir":"Articles","previous_headings":"Installation","what":"Install LLamaGPT-Chat","title":"Interact with local models","text":"LlamaGPT-Chat need “compiled binary” specific Operating System. example, Windows, compiled binary .exe file. GitHub repository offers pre-compiled binaries can download use: Releases. Depending system’s security, pre-compiled program may blocked running. case, need “build” program computer. instructions .","code":""},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"llm-file","dir":"Articles","previous_headings":"Installation","what":"LLM file","title":"Interact with local models","text":"GitHub repoisotry contains list compatible models. Download least one models, make note saved computer.","code":""},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Interact with local models","text":"start, instruct chattr switch LLamaGPT back-end using chattr_use() first time use interface, confirm path compiled program, model matches machine. check use chattr_defaults() either, , paths incorrect, correct updating path, model arguments chattr_defaults() need change defaults every time start new R session, use chattr_defaults_save(). create YAML file working directory. chattr use file override defaults. Use chattr_test() confirm chattr able communicate LLamaGPT-Chat, model use R session accessible","code":"library(chattr)  chattr_use(\"llamagpt\") #> • Provider: LlamaGPT #> • Model: ~/ggml-gpt4all-j-v1.3-groovy.bin chattr_defaults() #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Defaults for: Console ── #>  #> ── Prompt: #> • Use the R language, the tidyverse, and tidymodels #>  #> ── Model #> • Provider: LlamaGPT #> • Path: ~/LlamaGPTJ-chat/build/bin/chat #> • Model: ~/ggml-gpt4all-j-v1.3-groovy.bin #>  #> ── Model Arguments: #> • threads: 4 #> • temp: 0.01 #> • n_predict: 1000 #>  #> ── Context: #> Max Data Files: 0 #> Max Data Frames: 0 #> ✖ Chat History #> ✖ Document contents chattr_defaults(path = \"[path to compiled program]\", model = \"[path to model]\") #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Defaults for: Console ── #>  #> ── Prompt: #> • Use the R language, the tidyverse, and tidymodels #>  #> ── Model #> • Provider: LlamaGPT #> • Path: [path to compiled program] #> • Model: [path to model] #>  #> ── Model Arguments: #> • threads: 4 #> • temp: 0.01 #> • n_predict: 1000 #>  #> ── Context: #> Max Data Files: 0 #> Max Data Frames: 0 #> ✖ Chat History #> ✖ Document contents chattr_defaults_save() chattr_test() #> ✔ Model started sucessfully #> ✔ Model session closed sucessfully"},{"path":"https://mlverse.github.io/chattr/articles/backend-llamagpt.html","id":"model-arguments","dir":"Articles","previous_headings":"","what":"Model Arguments","title":"Interact with local models","text":"arguments sent model can modified chattr_defaults() modifying model_arguments argument. expects list object. arguments sets default: example adding batch_size defaults: see current list available model arguments go : Detailed command list. IMPORTANT - chattr passes arguments directly LLamaGPT-chat command line flag, except model. chattr use value chattr_defaults(model = \"[path model]\") instead.","code":"chattr_defaults()$model_arguments #> $threads #> [1] 4 #>  #> $temp #> [1] 0.01 #>  #> $n_predict #> [1] 1000 chattr_defaults(model_arguments = list(batch_size = 40)) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Defaults for: Console ── #>  #> ── Prompt: #> • Use the R language, the tidyverse, and tidymodels #>  #> ── Model #> • Provider: LlamaGPT #> • Path: [path to compiled program] #> • Model: [path to model] #>  #> ── Model Arguments: #> • batch_size: 40 #> • threads: 4 #> • temp: 0.01 #> • n_predict: 1000 #>  #> ── Context: #> Max Data Files: 0 #> Max Data Frames: 0 #> ✖ Chat History #> ✖ Document contents"},{"path":"https://mlverse.github.io/chattr/articles/prompt_defaults.html","id":"support-for-glue","dir":"Articles","previous_headings":"","what":"Support for glue","title":"Modify prompt enhancements","text":"prompt argument supports glue. means can pass current values variables, current output functions within current R session. Make sure output, value, character readable LLM. simple example function passes variables currently R session contain “x”: my_list() function passed prompt argument enclosed braces: Now can test , setting two variables start “x” see sent LLM, can use chattr(preview = TRUE). two variables listed part prompt: can see adding new variable modify prompt us modify chattr_defaults():","code":"my_list <- function() {   return(ls(pattern = \"x\", envir = globalenv())) } chattr_defaults(prompt = \"{ my_list() }\") #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Defaults for: Console ── #>  #> ── Prompt: #> • {{ my_list() }} #>  #> ── Model #> • Provider: Open AI - Chat Completions #> • Path: https://api.openai.com/v1/chat/completions #> • Model: gpt-4 #>  #> ── Model Arguments: #> • temperature: 0.01 #> • max_tokens: 1000 #> • stream: TRUE #>  #> ── Context: #> Max Data Files: 20 #> Max Data Frames: 20 #> ✔ Chat History #> ✖ Document contents x1 <- 1 x2 <- 2 chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: Open AI - Chat Completions #> • Model: gpt-4 #> • temperature: 0.01 #> • max_tokens: 1000 #> • stream: TRUE #>  #> ── Prompt: #> role: system #> content: You are a helpful coding assistant #> role: user #> content: #> * x1 #> * x2 #> [Your future prompt goes here] x3 <- 3  chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: Open AI - Chat Completions #> • Model: gpt-4 #> • temperature: 0.01 #> • max_tokens: 1000 #> • stream: TRUE #>  #> ── Prompt: #> role: system #> content: You are a helpful coding assistant #> role: user #> content: #> * x1 #> * x2 #> * x3 #> [Your future prompt goes here]"},{"path":"https://mlverse.github.io/chattr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Edgar Ruiz. Author, maintainer. Posit Software, PBC. Copyright holder, funder.","code":""},{"path":"https://mlverse.github.io/chattr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ruiz E (2023). chattr: Integrates LLM's RStudio IDE. https://github.com/mlverse/chattr, https://mlverse.github.io/chattr/.","code":"@Manual{,   title = {chattr: Integrates LLM's with the RStudio IDE},   author = {Edgar Ruiz},   year = {2023},   note = {https://github.com/mlverse/chattr, https://mlverse.github.io/chattr/}, }"},{"path":"https://mlverse.github.io/chattr/index.html","id":"chattr","dir":"","previous_headings":"","what":"Integrates LLM's with the RStudio IDE","title":"Integrates LLM's with the RStudio IDE","text":"Intro Available models Install Secret key Test connection App Keyboard Shortcut works setup keyboard shortcut","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"intro","dir":"","previous_headings":"","what":"Intro","title":"Integrates LLM's with the RStudio IDE","text":"chattr interface LLMs (Large Language Models). enables interaction model directly RStudio IDE. chattr allows submit prompt LLM script, using provided Shiny Gadget. chattr’s main goal aid EDA tasks. additional information appended request, provides sort “guard rails”, packages techniques usually recommend best practice, used model’s responses.","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"available-models","dir":"","previous_headings":"","what":"Available models","title":"Integrates LLM's with the RStudio IDE","text":"chattr provides two main integration two main LLM back-ends. back-end provides access multiple LLM types: idea time goes , back-ends added.","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"Integrates LLM's with the RStudio IDE","text":"Since early version package install package Github:","code":"remotes::install_github(\"edgararuiz/chattr\")"},{"path":[]},{"path":"https://mlverse.github.io/chattr/index.html","id":"secret-key","dir":"","previous_headings":"Getting Started","what":"Secret key","title":"Integrates LLM's with the RStudio IDE","text":"OpenAI requires secret key authenticate user. required application non-OpenAI application, chattr, one order function. key long alphanumeric sequence. sequence created OpenAI portal. obtain secret key, follow link: OpenAI API Keys default, chattr look secret key inside Environment Variable called OPENAI_API_KEY. packages integrate OpenAI use variable name. Use Sys.setenv() set variable. downside using method variable available current R session: preferred method save secret key .Renviron file. way, need load environment variable every time start new R session. .Renviron file available home directory. example entry:","code":"Sys.setenv(\"OPENAI_API_KEY\" = \"####################\") OPENAI_API_KEY=####################"},{"path":"https://mlverse.github.io/chattr/index.html","id":"test-connection","dir":"","previous_headings":"Getting Started","what":"Test connection","title":"Integrates LLM's with the RStudio IDE","text":"Use chattr_test() function confirm connection works:","code":"chattr_test() ✔ Connection with OpenAI cofirmed ✔ Access to models confirmed"},{"path":[]},{"path":"https://mlverse.github.io/chattr/index.html","id":"the-app","dir":"","previous_headings":"Using","what":"The App","title":"Integrates LLM's with the RStudio IDE","text":"main way use chattr Shiny Gadget app. default, runs inside Viewer pane. fastest way activate app calling via provided function: Screenshot Sniny gadget app dark mode RStudio theme lot effort put make app’s appearance close possible IDE. way feels integrated work space. includes switching color scheme based current RStudio theme light, dark. Automatically, app automatically add buttons code section. buttons lets us copy code clipboard, send document. “call” app Quarto document, app envelop code inside chunk.","code":"chattr::chattr_app()"},{"path":"https://mlverse.github.io/chattr/index.html","id":"keyboard-shortcut","dir":"","previous_headings":"Using","what":"Keyboard Shortcut","title":"Integrates LLM's with the RStudio IDE","text":"best way access chattr’s app setting keyboard shortcut . package includes RStudio Addin gives us direct access app, turn, allows keyboard shortcut assigned addin. name addin : “Open Chat”. familiar assign keyboard shortcut adding see Appendix section: setup keyboard shortcut.","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"how-it-works","dir":"","previous_headings":"","what":"How it works","title":"Integrates LLM's with the RStudio IDE","text":"chattr enriches request additional instructions, name structure data frames currently environment, path data files working directory. supported model, chattr include current chat history. Diagram illustrates chattr handles model requests see chattr send model, set preview argument TRUE:","code":"library(chattr)  data(mtcars) data(iris)  chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: Open AI - Chat Completions #> • Model: gpt-3.5-turbo #> • temperature: 0.01 #> • max_tokens: 1000 #> • stream: TRUE #>  #> ── Prompt: #> role: system #> content: You are a helpful coding assistant #> role: user #> content: #> * Use the 'Tidy Modeling with R' (https://www.tmwr.org/) book as main reference #> * Use the 'R for Data Science' (https://r4ds.had.co.nz/) book as main reference #> * Use tidyverse packages: readr, ggplot2, dplyr, tidyr #> * For models, use tidymodels packages: recipes, parsnip, yardstick, workflows, #> broom #> * Avoid explanations unless requested by user, expecting code only #> * Data files available: #> |- docs/deps/data-deps.txt #> |- inst/prompt/base.txt #> * Data frames currently in R memory (and columns): #> |-- iris (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species) #> |-- mtcars (mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb) #> [Your future prompt goes here]"},{"path":[]},{"path":"https://mlverse.github.io/chattr/index.html","id":"how-to-setup-the-keyboard-shortcut","dir":"","previous_headings":"Appendix","what":"How to setup the keyboard shortcut","title":"Integrates LLM's with the RStudio IDE","text":"Select Tools top menu, select Modify Keyboard Shortcuts  Search chattr adding writing “open chat”, search box  select key combination shortcut, click Shortcut box type press key combination keyboard. case, chose Ctrl+Shift+C","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":null,"dir":"Reference","previous_headings":"","what":"Displays the current session' chat history — ch_history","title":"Displays the current session' chat history — ch_history","text":"Displays current session' chat history","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Displays the current session' chat history — ch_history","text":"","code":"ch_history(x = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Displays the current session' chat history — ch_history","text":"x list object contains chat history. Use argument override current history.","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":null,"dir":"Reference","previous_headings":"","what":"Method to easily integrate to new LLM's — ch_submit","title":"Method to easily integrate to new LLM's — ch_submit","text":"Method easily integrate new LLM's","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method to easily integrate to new LLM's — ch_submit","text":"","code":"ch_submit(   defaults,   prompt = NULL,   stream = NULL,   prompt_build = TRUE,   preview = FALSE,   r_file_stream = NULL,   r_file_complete = NULL,   ... )  ch_submit_job(   prompt,   stream = NULL,   prompt_build = TRUE,   r_file_stream = tempfile(),   r_file_complete = tempfile(),   defaults = chattr_defaults(type = \"chat\") )  ch_submit_job_stop()"},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method to easily integrate to new LLM's — ch_submit","text":"defaults Defaults object, generally puled chattr_defaults() prompt prompt send LLM stream output response LLM happens, wait response complete. Defaults TRUE. prompt_build Include context additional prompt part request preview Primarily used debugging. indicates send prompt LLM (FALSE), print resulting prompt (TRUE) r_file_stream (Optional) Path save output current stream LLM r_file_complete (Optional) Path save completed output stream, response LLM ... Optional arguments; currently unused.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":null,"dir":"Reference","previous_headings":"","what":"Submits prompt to LLM — chattr","title":"Submits prompt to LLM — chattr","text":"Submits prompt LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submits prompt to LLM — chattr","text":"","code":"chattr(prompt = NULL, preview = FALSE, prompt_build = TRUE, stream = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submits prompt to LLM — chattr","text":"prompt Request send LLM. Defaults NULL preview Primarily used debugging. indicates send prompt LLM (FALSE), print resulting prompt (TRUE) prompt_build Include context additional prompt part request stream output response LLM happens, wait response complete. Defaults TRUE.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Starts a Shiny app interface to the LLM — chattr_app","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"Starts Shiny app interface LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"","code":"chattr_app(   viewer = c(\"viewer\", \"dialog\"),   as_job = FALSE,   as_job_port = getOption(\"shiny.port\", 7788),   as_job_host = getOption(\"shiny.host\", \"127.0.0.1\") )"},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"viewer Specifies Shiny app going display as_job App runs RStudio IDE Job. Defaults FALSE. set TRUE, Shiny app able transfer code blocks directly document, console, IDE. as_job_port Port use Shiny app. Applicable as_job set TRUE. as_job_host Host IP use Shiny app. Applicable as_job set TRUE.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Default arguments to use when making requests to the LLM — chattr_defaults","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"Default arguments use making requests LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"","code":"chattr_defaults(   type = NULL,   prompt = NULL,   max_data_files = NULL,   max_data_frames = NULL,   include_doc_contents = NULL,   include_history = NULL,   provider = NULL,   path = NULL,   model = NULL,   model_arguments = NULL,   system_msg = NULL,   yaml_file = \"chattr.yml\",   force = FALSE )"},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"type Entry point interact model. Accepted values: 'notebook', 'chat' prompt Request send LLM. Defaults NULL max_data_files Sets maximum number data files send model. defaults 20. send , set NULL max_data_frames Sets maximum number data frames loaded current R session send model. defaults 20. send , set NULL include_doc_contents Send current code document include_history Indicates weather include chat history everytime new prompt submitted provider name provider LLM. Today, \"openai\" available path location model. URL file path. model name path model use. model_arguments Additional arguments pass model part request, requires list. Examples arguments: temperature, top_p, max_tokens system_msg OpenAI GPT 3.5 , system message send part request yaml_file path valid config YAML file contains defaults use session force Re-process base work space level file defaults","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"idea use addin shortcut execute request, arguments can controlled via function. default, try load defaults config YAML file, none found, defaults GPT 3.5 used. defaults can modified calling function, even interactive session started.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves the current defaults in a yaml file that is compatible with\nthe config package — chattr_defaults_save","title":"Saves the current defaults in a yaml file that is compatible with\nthe config package — chattr_defaults_save","text":"Saves current defaults yaml file compatible config package","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves the current defaults in a yaml file that is compatible with\nthe config package — chattr_defaults_save","text":"","code":"chattr_defaults_save(path = \"chattr.yml\", overwrite = FALSE, type = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves the current defaults in a yaml file that is compatible with\nthe config package — chattr_defaults_save","text":"path Path file save configuration overwrite Indicates replace file exists type type UI save defaults . defaults NULL save whatever types used current R session","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirms conectivity to LLM interface — chattr_test","title":"Confirms conectivity to LLM interface — chattr_test","text":"Confirms conectivity LLM interface","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirms conectivity to LLM interface — chattr_test","text":"","code":"chattr_test(defaults = chattr_defaults())"},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confirms conectivity to LLM interface — chattr_test","text":"defaults Defaults object, generally puled chattr_defaults()","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the LLM model to use in your session — chattr_use","title":"Sets the LLM model to use in your session — chattr_use","text":"Sets LLM model use session","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the LLM model to use in your session — chattr_use","text":"","code":"chattr_use(model_label = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the LLM model to use in your session — chattr_use","text":"model_label label LLM model use. Valid values gpt35, davinci, llamagpt.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sets the LLM model to use in your session — chattr_use","text":"Use 'CHATTR_MODEL' environment variable set R session.","code":""}]
