[{"path":"https://mlverse.github.io/chattr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 chattr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://mlverse.github.io/chattr/articles/other-interfaces.html","id":"output","dir":"Articles","previous_headings":"","what":"Output","title":"Other interfaces","text":"Based making request , chattr return response appropriately following manner: request made R console, response returned console message, R code (cat()). way, can decide copy-paste code run. also prevent comments LLM cause error. request made script, code chunk Quarto (Visual editor), output inserted right prompt document.","code":""},{"path":"https://mlverse.github.io/chattr/articles/other-interfaces.html","id":"using-the-chattr-function","dir":"Articles","previous_headings":"","what":"Using the chattr() function","title":"Other interfaces","text":"fastest way interact LLM simply calling chattr() function enter request . example request made OpenAI:","code":"library(chattr) chattr(\"show me a simple recipe\") # Load required packages library(tidymodels)  # Create a simple recipe for the iris dataset iris_recipe <- recipe(Species ~ ., data = iris)   # Print the recipe iris_recipe"},{"path":"https://mlverse.github.io/chattr/articles/other-interfaces.html","id":"highlight-the-request-in-a-script","dir":"Articles","previous_headings":"","what":"Highlight the request in a script","title":"Other interfaces","text":"script, chattr process current line, highlighted line(s), prompt. assume request going code, chattr comment line lines highlighted. mentioned Output section, response inserted document. example request submitted OpenAI: results:","code":"Create a function that:   - Removes specified variables   - Behaves like dplyr's select function # Create a function that: #   - Removes specified variables #   - Behaves like dplyr's select function   # This function removes specified variables and behaves like dplyr's select function # It uses the tidyverse packages: dplyr and tidyr  remove_vars <- function(data, ...) {     data %>%         select(-one_of(...)) }   }"},{"path":"https://mlverse.github.io/chattr/articles/prompt_defaults.html","id":"support-for-glue","dir":"Articles","previous_headings":"","what":"Support for glue","title":"Modify prompt enhancements","text":"prompt argument supports glue. means can pass current values variables, current output functions within current R session. Make sure output, value, character readable LLM. simple example function passes variables currently R session contain “x”: my_list() function passed prompt argument enclosed braces: Now can test , setting two variables start “x” see sent LLM, can use chattr(preview = TRUE). two variables listed part prompt: can see adding new variable modify prompt us modify chattr_defaults():","code":"my_list <- function() {   return(ls(pattern = \"x\", envir = globalenv())) } chattr_defaults(prompt = \"{ my_list() }\") #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Defaults for: Default ── #>  #> ── Prompt: #> • {{ my_list() }} #>  #> ── Model #> • Provider: Ollama #> • Model: llama3.2 #> • Label: Llama 3.2 (Ollama) #>  #> ── Context: #> Max Data Files: 0 #> Max Data Frames: 0 #> ✖ Chat History #> ✖ Document contents x1 <- 1 x2 <- 2 chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: Ollama #> • Model: llama3.2 #> • Label: Llama 3.2 (Ollama) #>  #> ── Prompt: x3 <- 3  chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: Ollama #> • Model: llama3.2 #> • Label: Llama 3.2 (Ollama) #>  #> ── Prompt:"},{"path":"https://mlverse.github.io/chattr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Edgar Ruiz. Author, maintainer. Posit Software, PBC. Copyright holder, funder.","code":""},{"path":"https://mlverse.github.io/chattr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ruiz E (2025). chattr: Interact Large Language Models 'RStudio'. R package version 0.2.1.9000, https://github.com/mlverse/chattr.","code":"@Manual{,   title = {chattr: Interact with Large Language Models in 'RStudio'},   author = {Edgar Ruiz},   year = {2025},   note = {R package version 0.2.1.9000},   url = {https://github.com/mlverse/chattr}, }"},{"path":"https://mlverse.github.io/chattr/index.html","id":"chattr","dir":"","previous_headings":"","what":"Interact with Large Language Models in RStudio","title":"Interact with Large Language Models in RStudio","text":"Intro Install Available models App Additional ways interact works setup keyboard shortcut","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"intro","dir":"","previous_headings":"","what":"Intro","title":"Interact with Large Language Models in RStudio","text":"chattr interface LLMs (Large Language Models). enables interaction model directly RStudio Positron. chattr allows submit prompt LLM script, using provided Shiny Gadget. package’s main goal aid exploratory data analysis (EDA) tasks. additional information appended request, provides sort “guard rails”, packages techniques usually recommend best practice, used model’s responses.","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"Interact with Large Language Models in RStudio","text":"install CRAN version package use: wish use development version use:","code":"install.packages(\"chattr\") pak::pak(\"mlverse/chattr\")"},{"path":"https://mlverse.github.io/chattr/index.html","id":"using","dir":"","previous_headings":"","what":"Using","title":"Interact with Large Language Models in RStudio","text":"Starting version 0.3, chattr integrates LLM’s via ellmer package. ellmer growing list LLM integrations, including OpenAI, Gemini, Deepseek others. several ways let chattr know LLM use: Pre-set R option - Pass ellmer connection command wish use .chattr_chat option, example: options(.chattr_chat = ellmer::chat_claude()). add code .Rprofile, chattr use default model settings use every time start R session. Use usethis::edit_r_profile() command easily edit .Rprofile Use ellmer object - can pass ellmer chat object directly chattr_use(): Named model - pass one several pre-defined provider/model setups. setups represented labels set chattr. time, combinations cover 3 providers: OpenAI, Databricks, Ollama. use, simply pass label chattr_use. see full list available pre-defined combinations argument values see Available models. example, wish use OpenAI’s GPT 4.1 Nano model, simply pass corresponding label: Select one menu (legacy) - nothing passed chattr_use(), option set, chattr try create ellmer chat . try figure authentication tokens OpenAI, Databricks, checks Ollama running machine. chattr returns menu based providers able find:","code":"my_chat <- ellmer::chat_claude()   chattr_use(my_chat) chattr_use(\"gpt41-nano\") chattr_use()    ── chattr - Available models    Select the number of the model you would like to use:    1: Databricks - databricks-dbrx-instruct (databricks-dbrx)    2: Databricks - databricks-meta-llama-3-3-70b-instruct (databricks-meta-llama31-70b)    3: Databricks - databricks-mixtral-8x7b-instruct (databricks-mixtral8x7b)    4: OpenAI - Chat Completions - gpt-4.1-mini (gpt41-mini)    5: OpenAI - Chat Completions - gpt-4.1-nano (gpt41-nano)    6: OpenAI - Chat Completions - gpt-4.1 (gpt41)    7: OpenAI - Chat Completions - gpt-4o (gpt4o)    8: Ollama - llama3.2 (ollama)      Selection:"},{"path":"https://mlverse.github.io/chattr/index.html","id":"available-models","dir":"","previous_headings":"Using","what":"Available models","title":"Interact with Large Language Models in RStudio","text":"convenience, chattr contains provider/model combinations can use passing Use value chattr_use(): provider /model wish use listed table , can create ellmer chat connection directly. pass chat object chattr_use(). list providers currently available package: Anthropic’s Claude: ellmer::chat_claude() AWS Bedrock: ellmer::chat_bedrock() Azure OpenAI: ellmer::chat_azure() Databricks: ellmer::chat_databricks() DeepSeek: ellmer::chat_deepseek() GitHub model marketplace: ellmer::chat_github() Google Gemini: ellmer::chat_gemini() Groq: ellmer::chat_groq() Ollama: ellmer::chat_ollama() OpenAI: ellmer::chat_openai() OpenRouter: ellmer::chat_openrouter() perplexity.ai: ellmer::chat_perplexity() Snowflake Cortex: ellmer::chat_snowflake() VLLM: ellmer::chat_cortex_analyst()","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"the-app","dir":"","previous_headings":"Using","what":"The App","title":"Interact with Large Language Models in RStudio","text":"main way use chattr Shiny Gadget app. default, RStudio app run inside Viewer pane. Screenshot Sniny gadget app dark mode RStudio theme  LLM finishes response, chattr app processes markdown code chunks. place three convenience buttons: Copy clipboard - write code inside chunk clipboard. Copy document - copy-paste code directly app called . app started working script, chattr copy code script. Copy new script - creates new R script RStudio IDE, copies content chunk directly . useful LLM writes Shiny app lot effort put make app’s appearance close possible IDE. way feels integrated work space. includes switching color scheme based current RStudio theme light, dark. settings screen can accessed clicking “gear” button. screen opens contain following: Save Open chats - early experiment allow us save retrieve past chats. chattr save file RDS format. main objective feature, able see past chats, continue previous conversations LLM. Prompt settings - section can change additional information attached prompt. Including number max data files, data frames sent LLM. Screenshot Sniny gadget options","code":"chattr_use(\"ollama\") chattr_app()"},{"path":"https://mlverse.github.io/chattr/index.html","id":"additional-ways-to-interact","dir":"","previous_headings":"Using","what":"Additional ways to interact","title":"Interact with Large Language Models in RStudio","text":"Apart Shiny app, chattr provides two ways interact LLM. details, see: interfaces","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"how-it-works","dir":"","previous_headings":"","what":"How it works","title":"Interact with Large Language Models in RStudio","text":"chattr enriches request additional instructions, name structure data frames currently environment, path data files working directory. supported model, chattr include current chat history. Diagram illustrates chattr handles model requests see chattr send model, set preview argument TRUE:","code":"library(chattr)  data(mtcars) data(iris)  chattr_use(\"gpt4o\") #>  #> ── chattr #> • Provider: OpenAI - Chat Completions #> • Model: gpt-4o #> • Label: GPT 4 Omni (OpenAI)  chattr(preview = TRUE) #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console #> • Provider: OpenAI - Chat Completions #> • Model: gpt-4o #> • Label: GPT 4 Omni (OpenAI) #> • temperature: 0.01 #> • max_tokens: 1000 #> • stream: TRUE #>  #> ── Prompt: #> [Your future prompt goes here]"},{"path":"https://mlverse.github.io/chattr/index.html","id":"keyboard-shortcut","dir":"","previous_headings":"","what":"Keyboard Shortcut","title":"Interact with Large Language Models in RStudio","text":"best way access chattr’s app setting keyboard shortcut . package includes RStudio Addin gives us direct access app, turn, allows keyboard shortcut assigned addin. name addin : “Open Chat”. familiar assign keyboard shortcut see next section.","code":""},{"path":"https://mlverse.github.io/chattr/index.html","id":"how-to-setup-the-keyboard-shortcut","dir":"","previous_headings":"Keyboard Shortcut","what":"How to setup the keyboard shortcut","title":"Interact with Large Language Models in RStudio","text":"Select Tools top menu, select Modify Keyboard Shortcuts  Screenshot shows find option modify keyboard shortcuts Search chattr adding writing “open chat”, search box  Screenshot shows input addin search select key combination shortcut, click Shortcut box type press key combination keyboard. case, chose Ctrl+Shift+C  Screenshot shows interface looks like shortcut selected","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":null,"dir":"Reference","previous_headings":"","what":"Displays and sets the current session' chat history — ch_history","title":"Displays and sets the current session' chat history — ch_history","text":"Displays sets current session' chat history","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Displays and sets the current session' chat history — ch_history","text":"","code":"ch_history(x = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Displays and sets the current session' chat history — ch_history","text":"x list object contains chat history. Use argument override current history.","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Displays and sets the current session' chat history — ch_history","text":"list object current chat history","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_history.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Displays and sets the current session' chat history — ch_history","text":"","code":"library(chattr)  chattr_use(\"test\", stream = FALSE) #>  #> ── chattr  #> • Provider: test backend #> • Model: Test model #> • Label: Test  chattr(\"hello\") #> hello  # View history ch_history() #>  #> ── Prompt:  #> role: user #> content: hello #> role: assistant #> content: hello  # Save history to a file chat_file <- tempfile() saveRDS(ch_history(), chat_file)  # Reset history ch_history(list()) #>  #> ── Prompt:   # Re-load history ch_history(readRDS(chat_file)) #>  #> ── Prompt:  #> role: user #> content: hello #> role: assistant #> content: hello"},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":null,"dir":"Reference","previous_headings":"","what":"Method to integrate to new LLM API's — ch_submit","title":"Method to integrate to new LLM API's — ch_submit","text":"Method integrate new LLM API's","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method to integrate to new LLM API's — ch_submit","text":"","code":"ch_submit(   defaults,   prompt = NULL,   stream = NULL,   prompt_build = TRUE,   preview = FALSE,   ... )"},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method to integrate to new LLM API's — ch_submit","text":"defaults Defaults object, generally puled chattr_defaults() prompt prompt send LLM stream output response LLM happens, wait response complete. Defaults TRUE. prompt_build Include context additional prompt part request preview Primarily used debugging. indicates send prompt LLM (FALSE), print resulting prompt (TRUE) ... Optional arguments; currently unused.","code":""},{"path":"https://mlverse.github.io/chattr/reference/ch_submit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Method to integrate to new LLM API's — ch_submit","text":"output model currently use.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":null,"dir":"Reference","previous_headings":"","what":"Submits prompt to LLM — chattr","title":"Submits prompt to LLM — chattr","text":"Submits prompt LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Submits prompt to LLM — chattr","text":"","code":"chattr(prompt = NULL, preview = FALSE, prompt_build = TRUE, stream = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Submits prompt to LLM — chattr","text":"prompt Request send LLM. Defaults NULL preview Primarily used debugging. indicates send prompt LLM (FALSE), print resulting prompt (TRUE) prompt_build Include context additional prompt part request stream output response LLM happens, wait response complete. Defaults TRUE.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Submits prompt to LLM — chattr","text":"output LLM console, document script.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Submits prompt to LLM — chattr","text":"","code":"library(chattr) chattr_use(\"test\") #>  #> ── chattr  #> • Provider: test backend #> • Model: Test model #> • Label: Test chattr(\"hello\") #> hello chattr(\"hello\", preview = TRUE) #> hello #>  #> ── chattr ────────────────────────────────────────────────────────────────────── #>  #> ── Preview for: Console  #> • Provider: test backend #> • Model: Test model #> • Label: Test #> • n_predict: 1000 #>  #> ── Prompt:"},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Starts a Shiny app interface to the LLM — chattr_app","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"Starts Shiny app interface LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"","code":"chattr_app(   viewer = c(\"viewer\", \"dialog\"),   as_job = getOption(\"chattr.as_job\", FALSE),   as_job_port = getOption(\"shiny.port\", 7788),   as_job_host = getOption(\"shiny.host\", \"127.0.0.1\") )"},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"viewer Specifies Shiny app going display as_job App runs RStudio IDE Job. Defaults FALSE. set TRUE, Shiny app able transfer code blocks directly document, console, IDE. as_job_port Port use Shiny app. Applicable as_job set TRUE. as_job_host Host IP use Shiny app. Applicable as_job set TRUE.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Starts a Shiny app interface to the LLM — chattr_app","text":"chat interface inside 'RStudio' IDE","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Default arguments to use when making requests to the LLM — chattr_defaults","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"Default arguments use making requests LLM","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"","code":"chattr_defaults(   type = \"default\",   prompt = NULL,   max_data_files = NULL,   max_data_frames = NULL,   include_doc_contents = NULL,   include_history = NULL,   provider = NULL,   path = NULL,   model = NULL,   model_arguments = NULL,   system_msg = NULL,   yaml_file = \"chattr.yml\",   force = FALSE,   label = NULL,   ... )"},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"type Entry point interact model. Accepted values: 'notebook', chat' prompt Request send LLM. Defaults NULL max_data_files Sets maximum number data files send model. defaults 20. send , set NULL max_data_frames Sets maximum number data frames loaded current R session send model. defaults 20. send , set NULL include_doc_contents Send current code document include_history Indicates whether include chat history every time new prompt submitted provider name provider LLM. Today, \"openai\" available path location model. URL file path. model name path model use. model_arguments Additional arguments pass model part request, requires list. Examples arguments: temperature, top_p, max_tokens system_msg OpenAI GPT 3.5 , system message send part request yaml_file path valid config YAML file contains defaults use session force Re-process base work space level file defaults label Label display Shiny app, locations ... Additional model arguments standard models/backends","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"'ch_model' object contains current defaults used communicate LLM.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Default arguments to use when making requests to the LLM — chattr_defaults","text":"idea use addin shortcut execute request, arguments can controlled via function. default, try load defaults config YAML file, none found, defaults GPT 3.5 used. defaults can modified calling function, even interactive session started.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves the current defaults in a yaml file that is compatible with the config package — chattr_defaults_save","title":"Saves the current defaults in a yaml file that is compatible with the config package — chattr_defaults_save","text":"Saves current defaults yaml file compatible config package","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves the current defaults in a yaml file that is compatible with the config package — chattr_defaults_save","text":"","code":"chattr_defaults_save(path = \"chattr.yml\", overwrite = FALSE, type = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves the current defaults in a yaml file that is compatible with the config package — chattr_defaults_save","text":"path Path file save configuration overwrite Indicates replace file exists type type UI save defaults . defaults NULL save whatever types used current R session","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_defaults_save.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves the current defaults in a yaml file that is compatible with the config package — chattr_defaults_save","text":"creates YAML file defaults set current R session.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Confirms connectivity to LLM interface — chattr_test","title":"Confirms connectivity to LLM interface — chattr_test","text":"Confirms connectivity LLM interface","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confirms connectivity to LLM interface — chattr_test","text":"","code":"chattr_test(defaults = NULL)  ch_test(defaults = NULL)"},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confirms connectivity to LLM interface — chattr_test","text":"defaults Defaults object, generally puled chattr_defaults()","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confirms connectivity to LLM interface — chattr_test","text":"returns console massages status test.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the LLM model to use in your session — chattr_use","title":"Sets the LLM model to use in your session — chattr_use","text":"Sets LLM model use session","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the LLM model to use in your session — chattr_use","text":"","code":"chattr_use(x = NULL, ...)"},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the LLM model to use in your session — chattr_use","text":"x pre-determined provider/model name, ellmer Chat object, path YAML file contains valid chattr model specification. value 'test' also acceptable, meant package examples, internal testing. See 'Details' information. ... Default values modify.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets the LLM model to use in your session — chattr_use","text":"returns console messages allow user select model use.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sets the LLM model to use in your session — chattr_use","text":"valid pre-determined provider/models values : 'databricks-dbrx', 'databricks-meta-llama31-70b', 'databricks-mixtral8x7b', 'gpt41-mini', 'gpt41-nano', 'gpt41', 'gpt4o', 'ollama'. need provider, model, available pre-determined value, create ellmer chat object pass chattr_use(). list valid models found : https://ellmer.tidyverse.org/index.html#providers","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"set-a-default","dir":"Reference","previous_headings":"","what":"Set a default","title":"Sets the LLM model to use in your session — chattr_use","text":"can setup R option designate default provider/model connection. , pass ellmer connection command wish use .chattr_chat option, example: options(.chattr_chat = ellmer::chat_claude()). add code  .Rprofile, chattr use default model settings use every time start R session. Use usethis::edit_r_profile() command easily edit .Rprofile.","code":""},{"path":"https://mlverse.github.io/chattr/reference/chattr_use.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets the LLM model to use in your session — chattr_use","text":"","code":"if (FALSE) { # \\dontrun{  # Use a valid provider/model label chattr_use(\"gpt41-mini\")  # Pass an `ellmer` object my_chat <- ellmer::chat_claude() chattr_use(my_chat) } # }"},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"chattr-021","dir":"Changelog","previous_headings":"","what":"chattr 0.2.1","title":"chattr 0.2.1","text":"CRAN release: 2025-01-30 Prevents OpenAI 4o showing option token found","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"chattr-020","dir":"Changelog","previous_headings":"","what":"chattr 0.2.0","title":"chattr 0.2.0","text":"CRAN release: 2024-07-29","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"general-0-2-0","dir":"Changelog","previous_headings":"","what":"General","title":"chattr 0.2.0","text":"Fixes identifies user’s current UI (console, app, notebook) appropriately outputs response model end-point (#92)","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"databricks-0-2-0","dir":"Changelog","previous_headings":"","what":"Databricks","title":"chattr 0.2.0","text":"Adding support Databricks foundation model API (DBRX, Meta Llama 3 70B, Mixtral 8x7B) (#99)","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"openai-0-2-0","dir":"Changelog","previous_headings":"","what":"OpenAI","title":"chattr 0.2.0","text":"Fixes displays error model end-point used notebook app Fixes errors OpenAI parsed processed. make easier users determine downstream issue .","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"copilot-0-2-0","dir":"Changelog","previous_headings":"","what":"Copilot","title":"chattr 0.2.0","text":"Adds model defaults Improves token discovery","code":""},{"path":"https://mlverse.github.io/chattr/news/index.html","id":"chattr-010","dir":"Changelog","previous_headings":"","what":"chattr 0.1.0","title":"chattr 0.1.0","text":"CRAN release: 2024-04-27 Initial CRAN submission.","code":""}]
