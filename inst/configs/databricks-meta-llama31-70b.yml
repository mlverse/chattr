default:
  ellmer: ellmer::chat_databricks(model = "databricks-meta-llama-3-3-70b-instruct")
  provider: Databricks
  path: serving-endpoints
  model: databricks-meta-llama-3-3-70b-instruct
  label: Meta Llama 3.3 70B (Databricks)
  max_data_files: 0
  max_data_frames: 0
  include_doc_contents: FALSE
  include_history: TRUE
  system_msg: |
    {readLines(system.file('prompt/base.txt', package = 'chattr'))}
    You are a helpful coding assistant that uses R and the tidyverse
  model_arguments:
    temperature: 0.01
    max_tokens: 1000
    stream: TRUE
chat:
  prompt: |
    For code output, use RMarkdown code chunks
    Avoid all code chunk options
console:
  prompt: |
    For any line that is not code, prefix with a: #
    Keep each line of explanations to no more than 80 characters
    DO NOT use Markdown for the code
script:
  prompt: |
    For any line that is not code, prefix with a: #
    Keep each line of explanations to no more than 80 characters
    DO NOT use Markdown for the code
