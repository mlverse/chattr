default:
  prompt: |
    {tc_base_prompt}
  provider: Open AI
  model: GPT 3.5 Turbo
  include_data_files: TRUE
  include_data_frames: TRUE
  include_doc_contents: FALSE
  include_history: TRUE
  system_msg: You are a helpful coding assistant
  model_arguments:
    temperature: 0.01
    max_tokens: 1000
    stream: TRUE
notebook:
  prompt: |
    {tidychat::tc_base_prompt}
    For code output, use RMarkdown code chunks, turn off evaluation in all chunks
    Include alt text code chunk option for all plots
chat:
  prompt: |
    {tidychat::tc_base_prompt}
    For code output, use markdown code chunks
console:
  prompt: |
    {tidychat::tc_base_prompt}
    For any line that is not code, prefix it with a: #
