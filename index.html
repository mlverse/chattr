<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Interact with Large Language Models in RStudio • chattr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
<link rel="icon" sizes="any" href="favicon.ico">
<link rel="manifest" href="site.webmanifest">
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Interact with Large Language Models in RStudio">
<meta name="description" content="Enables user interactivity with large-language models (LLM) inside the RStudio integrated development environment (IDE). The user can interact with the model using the shiny app included in this package, or directly in the R console. It comes with back-ends for OpenAI, GitHub Copilot, and LlamaGPT.">
<meta property="og:description" content="Enables user interactivity with large-language models (LLM) inside the RStudio integrated development environment (IDE). The user can interact with the model using the shiny app included in this package, or directly in the R console. It comes with back-ends for OpenAI, GitHub Copilot, and LlamaGPT.">
<meta property="og:image" content="https://mlverse.github.io/chattr/logo.png">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">chattr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="articles/other-interfaces.html">Other interfaces</a></li>
    <li><a class="dropdown-item" href="articles/prompt_defaults.html">Modify prompt enhancements</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/chattr/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header">
<img src="logo.png" class="logo" alt=""><h1 id="chattr">chattr<a class="anchor" aria-label="anchor" href="#chattr"></a>
</h1>
</div>
<!-- badges: start -->

<!-- toc: start -->
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#install">Install</a></li>
<li>
<a href="#using">Using</a>
<ul>
<li><a href="#available-models">Available models</a></li>
<li><a href="#the-app">The App</a></li>
<li><a href="#additional-ways-to-interact">Additional ways to interact</a></li>
</ul>
</li>
<li><a href="#how-it-works">How it works</a></li>
<li>
<a href="#keyboard-shortcut">Keyboard Shortcut</a>
<ul>
<li><a href="#how-to-setup-the-keyboard-shortcut">How to setup the keyboard shortcut</a></li>
</ul>
</li>
</ul>
<!-- toc: end --><div class="section level2">
<h2 id="intro">Intro<a class="anchor" aria-label="anchor" href="#intro"></a>
</h2>
<p><code>chattr</code> is an interface to LLMs (Large Language Models). It enables interaction with the model directly from RStudio and Positron. <code>chattr</code> allows you to submit a prompt to the LLM from your script, or by using the provided Shiny Gadget.</p>
<p>This package’s main goal is to aid in exploratory data analysis (EDA) tasks. The additional information appended to your request, provides a sort of “guard rails”, so that the packages and techniques we usually recommend as best practice, are used in the model’s responses.</p>
</div>
<div class="section level2">
<h2 id="install">Install<a class="anchor" aria-label="anchor" href="#install"></a>
</h2>
<p>To install the CRAN version of this package use:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"chattr"</span><span class="op">)</span></span></code></pre></div>
<p>If you wish to use the development version use:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">pak</span><span class="fu">::</span><span class="fu"><a href="https://pak.r-lib.org/reference/pak.html" class="external-link">pak</a></span><span class="op">(</span><span class="st">"mlverse/chattr"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="using">Using<a class="anchor" aria-label="anchor" href="#using"></a>
</h2>
<p>Starting with version 0.3, <code>chattr</code> integrates with LLM’s via the <a href="https://ellmer.tidyverse.org/" class="external-link"><code>ellmer</code></a> package. <code>ellmer</code> has a growing list of LLM integrations, including <a href="https://ellmer.tidyverse.org/reference/chat_openai.html" class="external-link">OpenAI</a>, <a href="https://ellmer.tidyverse.org/reference/chat_gemini.html" class="external-link">Gemini</a>, <a href="https://ellmer.tidyverse.org/reference/chat_deepseek.html" class="external-link">Deepseek</a> and others.</p>
<p>There are several ways to let <code>chattr</code> know which LLM to use:</p>
<ul>
<li><p><strong>Pre-set an R option</strong> - Pass the <code>ellmer</code> connection command you wish to use in the <code>.chattr_chat</code> option, for example: <code>options(.chattr_chat = ellmer::chat_anthropic())</code>. If you add that code to your <em>.Rprofile</em>, <code>chattr</code> will use that as the default model and settings to use every time you start an R session. Use the <code>usethis::edit_r_profile()</code> command to easily edit your <em>.Rprofile</em></p></li>
<li>
<p><strong>Use an <code>ellmer</code> object</strong> - You can pass an <code>ellmer</code> chat object directly to <code><a href="reference/chattr_use.html">chattr_use()</a></code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="va">my_chat</span> <span class="op">&lt;-</span> <span class="fu">ellmer</span><span class="fu">::</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_anthropic.html" class="external-link">chat_anthropic</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="reference/chattr_use.html">chattr_use</a></span><span class="op">(</span><span class="va">my_chat</span><span class="op">)</span></span></code></pre></div>
</li>
<li>
<p><strong>Named model</strong> - You pass one of several pre-defined provider/model setups. These setups are represented by labels set by <code>chattr</code>. At this time, the combinations cover 3 providers: OpenAI, Databricks, and Ollama. To use, simply pass the label to <code>chattr_use</code>. To see a full list of the available pre-defined combinations and their argument values see <a href="#available-models">Available models</a>. For example, if you wish to use OpenAI’s GPT 4.1 Nano model, you simply pass the corresponding label:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="reference/chattr_use.html">chattr_use</a></span><span class="op">(</span><span class="st">"gpt41-nano"</span><span class="op">)</span></span></code></pre></div>
</li>
<li>
<p><strong>Select one from a menu (legacy)</strong> - If nothing is passed to <code><a href="reference/chattr_use.html">chattr_use()</a></code>, and no option is set, <code>chattr</code> will try to create the <code>ellmer</code> chat for you. It will try to figure if you have authentication tokens for <strong>OpenAI</strong>, <strong>Databricks</strong>, and checks if <strong>Ollama</strong> is running on your machine. <code>chattr</code> then returns a menu based on the providers it was able to find:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>  <span class="fu">chattr_use</span>()</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  ── chattr <span class="sc">-</span> Available models </span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  Select the number of the model you would like to use<span class="sc">:</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>  <span class="dv">1</span><span class="sc">:</span> Databricks <span class="sc">-</span> databricks<span class="sc">-</span>dbrx<span class="sc">-</span><span class="fu">instruct</span> (databricks<span class="sc">-</span>dbrx) </span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>  <span class="dv">2</span><span class="sc">:</span> Databricks <span class="sc">-</span> databricks<span class="sc">-</span>meta<span class="sc">-</span>llama<span class="dv">-3-3-70</span>b<span class="sc">-</span><span class="fu">instruct</span> (databricks<span class="sc">-</span>meta<span class="sc">-</span>llama31<span class="dv">-70</span>b) </span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>  <span class="dv">3</span><span class="sc">:</span> Databricks <span class="sc">-</span> databricks<span class="sc">-</span>mixtral<span class="dv">-8</span>x7b<span class="sc">-</span><span class="fu">instruct</span> (databricks<span class="sc">-</span>mixtral8x7b) </span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>  <span class="dv">4</span><span class="sc">:</span> OpenAI <span class="sc">-</span> Chat Completions <span class="sc">-</span> gpt<span class="fl">-4.1</span><span class="sc">-</span><span class="fu">mini</span> (gpt41<span class="sc">-</span>mini) </span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>  <span class="dv">5</span><span class="sc">:</span> OpenAI <span class="sc">-</span> Chat Completions <span class="sc">-</span> gpt<span class="fl">-4.1</span><span class="sc">-</span><span class="fu">nano</span> (gpt41<span class="sc">-</span>nano) </span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>  <span class="dv">6</span><span class="sc">:</span> OpenAI <span class="sc">-</span> Chat Completions <span class="sc">-</span> gpt<span class="fl">-4.1</span> (gpt41) </span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>  <span class="dv">7</span><span class="sc">:</span> OpenAI <span class="sc">-</span> Chat Completions <span class="sc">-</span> gpt<span class="dv">-4</span><span class="fu">o</span> (gpt4o) </span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>  <span class="dv">8</span><span class="sc">:</span> Ollama <span class="sc">-</span> <span class="fu">llama3.2</span> (ollama) </span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>  Selection<span class="sc">:</span> </span></code></pre></div>
</li>
</ul>
<div class="section level3">
<h3 id="available-models">Available models<a class="anchor" aria-label="anchor" href="#available-models"></a>
</h3>
<p>For convenience, <code>chattr</code> contains some provider/model combinations that you can use by passing what is under <strong>Use value</strong> to <code><a href="reference/chattr_use.html">chattr_use()</a></code>:</p>
<!-- models: start -->
<table class="table">
<thead><tr>
<th>
Model &amp; Provider
</th>
<th>
Use value
</th>
</tr></thead>
<tbody>
<tr>
<td>
DBRX (Databricks)
</td>
<td>
<code>databricks-dbrx</code>
</td>
</tr>
<tr>
<td>
Meta Llama 3.3 70B (Databricks)
</td>
<td>
<code>databricks-meta-llama31-70b</code>
</td>
</tr>
<tr>
<td>
Mixtral 8x7b (Datbricks)
</td>
<td>
<code>databricks-mixtral8x7b</code>
</td>
</tr>
<tr>
<td>
GPT 4.1 Mini (OpenAI)
</td>
<td>
<code>gpt41-mini</code>
</td>
</tr>
<tr>
<td>
GPT 4.1 Nano (OpenAI)
</td>
<td>
<code>gpt41-nano</code>
</td>
</tr>
<tr>
<td>
GPT 4.1 (OpenAI)
</td>
<td>
<code>gpt41</code>
</td>
</tr>
<tr>
<td>
GPT 4 Omni (OpenAI)
</td>
<td>
<code>gpt4o</code>
</td>
</tr>
<tr>
<td>
Llama 3.2 (Ollama)
</td>
<td>
<code>ollama</code>
</td>
</tr>
</tbody>
</table>
<!-- 'databricks-dbrx', 'databricks-meta-llama31-70b', 'databricks-mixtral8x7b', 'gpt41-mini', 'gpt41-nano', 'gpt41', 'gpt4o', 'ollama'--><!-- models: end --><p>If the provider and/or model you wish to use is not listed in the table above, you can create an <code>ellmer</code> chat connection directly. And then pass that chat object to <code><a href="reference/chattr_use.html">chattr_use()</a></code>. Here is a list of the providers that are currently available in that package:</p>
<!-- providers: start -->
<ul>
<li>Anthropic’s Claude: <a href="https://ellmer.tidyverse.org/reference/chat_anthropic.html" class="external-link"><code>ellmer::chat_anthropic()</code></a>
</li>
<li>AWS Bedrock: <a href="https://ellmer.tidyverse.org/reference/chat_aws_bedrock.html" class="external-link"><code>ellmer::chat_aws_bedrock()</code></a>
</li>
<li>Azure OpenAI: <a href="https://ellmer.tidyverse.org/reference/chat_azure_openai.html" class="external-link"><code>ellmer::chat_azure_openai()</code></a>
</li>
<li>Cloudflare: <a href="https://ellmer.tidyverse.org/reference/chat_cloudflare.html" class="external-link"><code>ellmer::chat_cloudflare()</code></a>
</li>
<li>Databricks: <a href="https://ellmer.tidyverse.org/reference/chat_databricks.html" class="external-link"><code>ellmer::chat_databricks()</code></a>
</li>
<li>DeepSeek: <a href="https://ellmer.tidyverse.org/reference/chat_deepseek.html" class="external-link"><code>ellmer::chat_deepseek()</code></a>
</li>
<li>GitHub model marketplace: <a href="https://ellmer.tidyverse.org/reference/chat_github.html" class="external-link"><code>ellmer::chat_github()</code></a>
</li>
<li>Google Gemini/Vertex AI: <a href="https://ellmer.tidyverse.org/reference/chat_google_gemini.html" class="external-link"><code>ellmer::chat_google_gemini()</code></a>
</li>
<li>Groq: <a href="https://ellmer.tidyverse.org/reference/chat_google_gemini.html" class="external-link"><code>ellmer::chat_google_vertex()</code></a>
</li>
<li>Hugging Face: <a href="https://ellmer.tidyverse.org/reference/chat_groq.html" class="external-link"><code>ellmer::chat_groq()</code></a>
</li>
<li>Mistral: <a href="https://ellmer.tidyverse.org/reference/chat_huggingface.html" class="external-link"><code>ellmer::chat_huggingface()</code></a>
</li>
<li>Ollama: <a href="https://ellmer.tidyverse.org/reference/chat_mistral.html" class="external-link"><code>ellmer::chat_mistral()</code></a>
</li>
<li>OpenAI: <a href="https://ellmer.tidyverse.org/reference/chat_ollama.html" class="external-link"><code>ellmer::chat_ollama()</code></a>
</li>
<li>OpenRouter: <a href="https://ellmer.tidyverse.org/reference/chat_openai.html" class="external-link"><code>ellmer::chat_openai()</code></a>
</li>
<li>perplexity.ai: <a href="https://ellmer.tidyverse.org/reference/chat_openrouter.html" class="external-link"><code>ellmer::chat_openrouter()</code></a>
</li>
<li>Snowflake Cortex: <a href="https://ellmer.tidyverse.org/reference/chat_perplexity.html" class="external-link"><code>ellmer::chat_perplexity()</code></a>
</li>
<li>VLLM: <a href="https://ellmer.tidyverse.org/reference/chat_snowflake.html" class="external-link"><code>ellmer::chat_snowflake()</code></a> <!-- providers: end -->
</li>
</ul>
</div>
<div class="section level3">
<h3 id="the-app">The App<a class="anchor" aria-label="anchor" href="#the-app"></a>
</h3>
<p>The main way to use <code>chattr</code> is through the Shiny Gadget app. By default, in RStudio the app will run inside the Viewer pane.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/chattr_use.html">chattr_use</a></span><span class="op">(</span><span class="st">"ollama"</span><span class="op">)</span></span>
<span><span class="fu"><a href="reference/chattr_app.html">chattr_app</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<figure><img src="reference/figures/readme/chat1.png" alt="Screenshot of the Sniny gadget app in a dark mode RStudio theme"><figcaption aria-hidden="true">
Screenshot of the Sniny gadget app in a dark mode RStudio theme
</figcaption></figure><p><br></p>
<p>After the LLM finishes its response, the <code>chattr</code> app processes all markdown code chunks. It will place three convenience buttons:</p>
<ul>
<li><p><strong>Copy to clipboard</strong> - It will write the code inside the chunk to your clipboard.</p></li>
<li><p><strong>Copy to document</strong> - It will copy-paste the code directly to where the app was called from. If the app is started while working on a script, <code>chattr</code> will copy the code to that same script.</p></li>
<li><p><strong>Copy to new script</strong> - It creates a new R script in the RStudio IDE, and copies the content of the chunk directly to it. Very useful when the LLM writes a Shiny app for you</p></li>
</ul>
<p>A lot of effort was put in to make the app’s appearance as close as possible to the IDE. This way it feels more integrated with your work space. This includes switching the color scheme based on the current RStudio theme being light, or dark.</p>
<p>The settings screen can be accessed by clicking on the “gear” button. The screen that opens will contain the following:</p>
<ul>
<li><p>Save and Open chats - This is an early experiment to allow us to save and retrieve past chats. <code>chattr</code> will save the file in an RDS format. The main objective of this feature, is to be able to see past chats, not to continue previous conversations with the LLM.</p></li>
<li><p>Prompt settings - In this section you can change the additional information attached to your prompt. Including the number of max data files, and data frames sent to the LLM.</p></li>
</ul>
<figure><img src="reference/figures/readme/chat2.png" alt="Screenshot of the Sniny gadget options"><figcaption aria-hidden="true">
Screenshot of the Sniny gadget options
</figcaption></figure>
</div>
<div class="section level3">
<h3 id="additional-ways-to-interact">Additional ways to interact<a class="anchor" aria-label="anchor" href="#additional-ways-to-interact"></a>
</h3>
<p>Apart from the Shiny app, <code>chattr</code> provides two more ways to interact with the LLM. For details, see: <a href="https://mlverse.github.io/chattr/articles/other-interfaces.html">Other interfaces</a></p>
</div>
</div>
<div class="section level2">
<h2 id="how-it-works">How it works<a class="anchor" aria-label="anchor" href="#how-it-works"></a>
</h2>
<p><code>chattr</code> enriches your request with additional instructions, name and structure of data frames currently in your environment, the path for the data files in your working directory. If supported by the model, <code>chattr</code> will include the current chat history.</p>
<figure><img src="reference/figures/readme/chattr-diagram.png" alt="Diagram that illustrates how chattr handles model requests"><figcaption aria-hidden="true">
Diagram that illustrates how <code>chattr</code> handles model requests
</figcaption></figure><p>To see what <code>chattr</code> will send to the model, set the <code>preview</code> argument to <code>TRUE</code>:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/mlverse/chattr" class="external-link">chattr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="reference/chattr_use.html">chattr_use</a></span><span class="op">(</span><span class="st">"gpt4o"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ── chattr</span></span>
<span><span class="co">#&gt; • Provider: OpenAI - Chat Completions</span></span>
<span><span class="co">#&gt; • Model: gpt-4o</span></span>
<span><span class="co">#&gt; • Label: GPT 4 Omni (OpenAI)</span></span>
<span></span>
<span><span class="fu"><a href="reference/chattr.html">chattr</a></span><span class="op">(</span>preview <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ── chattr ──────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ── Preview for: Console</span></span>
<span><span class="co">#&gt; • Provider: OpenAI - Chat Completions</span></span>
<span><span class="co">#&gt; • Model: gpt-4o</span></span>
<span><span class="co">#&gt; • Label: GPT 4 Omni (OpenAI)</span></span>
<span><span class="co">#&gt; • temperature: 0.01</span></span>
<span><span class="co">#&gt; • max_tokens: 1000</span></span>
<span><span class="co">#&gt; • stream: TRUE</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ── Prompt:</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="keyboard-shortcut">Keyboard Shortcut<a class="anchor" aria-label="anchor" href="#keyboard-shortcut"></a>
</h2>
<p>The best way to access <code>chattr</code>’s app is by setting up a keyboard shortcut for it. This package includes an RStudio Addin that gives us direct access to the app, which in turn, allows a <strong>keyboard shortcut</strong> to be assigned to the addin. The name of the addin is: “Open Chat”. If you are not familiar with how to assign a keyboard shortcut see the next section.</p>
<div class="section level3">
<h3 id="how-to-setup-the-keyboard-shortcut">How to setup the keyboard shortcut<a class="anchor" aria-label="anchor" href="#how-to-setup-the-keyboard-shortcut"></a>
</h3>
<ul>
<li>
<p>Select <em>Tools</em> in the top menu, and then select <em>Modify Keyboard Shortcuts</em></p>
<figure><p><img src="reference/figures/readme/keyboard-shortcuts.png" width="700" alt="Screenshot that shows where to find the option to modify the keyboard shortcuts"></p>
<figcaption aria-hidden="true"><p>Screenshot that shows where to find the option to modify the keyboard shortcuts</p>
</figcaption></figure>
</li>
<li>
<p>Search for the <code>chattr</code> adding by writing “open chat”, in the search box</p>
<figure><p><img src="reference/figures/readme/addin-find.png" width="500" alt="Screenshot that shows where to input the addin search"></p>
<figcaption aria-hidden="true"><p>Screenshot that shows where to input the addin search</p>
</figcaption></figure>
</li>
<li>
<p>To select a key combination for your shortcut, click on the Shortcut box and then type <em>press</em> the key combination in your keyboard. In my case, I chose <em>Ctrl+Shift+C</em></p>
<figure><p><img src="reference/figures/readme/addin-assign.png" width="500" alt="Screenshot that shows what the interface looks like when a shortcut has been selected"></p>
<figcaption aria-hidden="true"><p>Screenshot that shows what the interface looks like when a shortcut has been selected</p>
</figcaption></figure>
</li>
</ul>
</div>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=chattr" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/mlverse/chattr/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/mlverse/chattr/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing chattr</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Edgar Ruiz <br><small class="roles"> Author, maintainer </small>   </li>
<li>Posit Software, PBC <br><small class="roles"> Copyright holder, funder </small>   </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://cran.r-project.org/package=chattr" data-original-href="https://cran.r-project.org/package=chattr" class="external-link"><img src="https://www.r-pkg.org/badges/version/chattr" alt="CRAN status" class="img-fluid"></a></li>
<li><a href="https://github.com/mlverse/chattr/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/mlverse/chattr/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://app.codecov.io/gh/mlverse/chattr?branch=main" class="external-link"><img src="https://codecov.io/gh/mlverse/chattr/branch/main/graph/badge.svg" alt="Codecov test coverage"></a></li>
<li><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental" class="external-link"><img src="reference/figures/lifecycle-experimental.svg"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Edgar Ruiz, Posit Software, PBC.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
